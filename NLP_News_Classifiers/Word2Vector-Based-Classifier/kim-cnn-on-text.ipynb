{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Kim-CNN Word2Vec-based Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from gensim) (1.26.3)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from gensim) (1.11.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.8.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import KeyedVectors\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploring The Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the Text File\n",
    "file_path = 'data.csv'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    news = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.countplot(x='label',data=news)\n",
    "plt.title(\"Distrbution of labels\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Frequancy\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Split the data into Traine - Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate the features and the target variable\n",
    "X = news['text']\n",
    "y = news['label']               \n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Preprocess Your Data**\n",
    "\n",
    "**Tokenization & Padding:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen max sequence length (95th percentile): 868\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# 1. a. Tokenize the train text\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(x_train)\n",
    "\n",
    "# 1. b. Tokenize the train text\n",
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "# 2. Compute the 95th percentile of these lengths\n",
    "train_sequence_lengths = [len(seq) for seq in sequences_train]\n",
    "max_length = int(np.percentile(train_sequence_lengths, 95))\n",
    "print(\"Chosen max sequence length (95th percentile):\", max_length)\n",
    "\n",
    "# 3. Use the max length as the max_sequence_length for padding/truncation\n",
    "max_sequence_length = max_length\n",
    "x_train = pad_sequences(sequences_train, maxlen=max_sequence_length)\n",
    "\n",
    "max_sequence_length = max_length\n",
    "x_test = pad_sequences(sequences_test, maxlen=max_sequence_length)\n",
    "\n",
    "word_index = tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load word2vec modle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"../models/GoogleNews-vectors-negative300.bin.gz\"\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Prepare the Embedding Layer**\n",
    "\n",
    "**Embedding Matrix from Pre-trained Word2Vec:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_dim = 300  # Google News word2vec using 300D\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec_model:\n",
    "        embedding_matrix[i] = word2vec_model[word]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create an Embedding layer in Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\007T\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    input_dim=len(word_index) + 1,\n",
    "    output_dim=embedding_dim,\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=max_sequence_length,\n",
    "    trainable=False  # Use False to keep the embeddings fixed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Build the Kim-CNN Architecture**\n",
    "\n",
    "**Architecture Components:**\n",
    "\n",
    "**1. Input Layer:** Accepts the padded sequences.\n",
    "\n",
    "**2. Embedding Layer:** Converts word indices to word vectors.\n",
    "\n",
    "**3. Convolutional Layers:** Apply several 1D convolution filters with different kernel sizes (e.g., 3, 4, 5) to capture various n-gram features.\n",
    "\n",
    "**4. Global Max-Pooling:** For each filter, apply max pooling over the time dimension (i.e., across the sentence length) to capture the most significant feature.\n",
    "\n",
    "**5. Concatenation:** Merge the outputs of the different filters.\n",
    "\n",
    "**6. Dropout:** Apply dropout for regularization.\n",
    "\n",
    "**7. Dense Layer:** Final classification layer with a softmax (or sigmoid) activation for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">868</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">868</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">35,320,500</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">866</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">115,328</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">865</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">153,728</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">864</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">192,128</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooli… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n",
       "│                     │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">770</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m868\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m868\u001b[0m, \u001b[38;5;34m300\u001b[0m)  │ \u001b[38;5;34m35,320,500\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m866\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m115,328\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m865\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m153,728\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m864\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m192,128\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_max_pooli… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_max_pooli… │\n",
       "│                     │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │        \u001b[38;5;34m770\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,782,454</span> (136.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m35,782,454\u001b[0m (136.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">461,954</span> (1.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m461,954\u001b[0m (1.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,320,500</span> (134.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m35,320,500\u001b[0m (134.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, GlobalMaxPooling1D, Concatenate, Dropout, Dense\n",
    "\n",
    "# Define hyperparameters\n",
    "filter_sizes = [3, 4, 5]   # Different filter sizes for n-grams\n",
    "num_filters = 128          # Number of filters per size\n",
    "dropout_rate = 0.5\n",
    "num_classes = 2            # Adjust based on your classification task\n",
    "\n",
    "# Input layer\n",
    "sequence_input = Input(shape=(max_sequence_length,), dtype='int32')\n",
    "\n",
    "# Embedding layer (using the pre-trained word2vec embeddings)\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "# Create a convolution + pooling layer for each filter size\n",
    "conv_layers = []\n",
    "for filter_size in filter_sizes:\n",
    "    conv = Conv1D(\n",
    "        filters=num_filters,\n",
    "        kernel_size=filter_size,\n",
    "        activation='relu'\n",
    "    )(embedded_sequences)\n",
    "    \n",
    "    pool = GlobalMaxPooling1D()(conv)\n",
    "    conv_layers.append(pool)\n",
    "\n",
    "# Concatenate the pooled features from each filter\n",
    "if len(conv_layers) > 1:\n",
    "    merged = Concatenate()(conv_layers)\n",
    "else:\n",
    "    merged = conv_layers[0]\n",
    "\n",
    "# Apply dropout for regularization\n",
    "drop = Dropout(dropout_rate)(merged)\n",
    "\n",
    "# Final dense layer for classification\n",
    "preds = Dense(num_classes, activation='softmax')(drop)\n",
    "\n",
    "# Define the model\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31953, 868) (31953,)\n",
      "(7989, 868) (7989,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer-on-text.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and Evaluating the Model**\n",
    "\n",
    "Convert your labels to categorical format and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert binary labels (0 or 1) to one-hot encoded vectors (shape becomes (num_samples, 2))\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8829 - loss: 0.2447\n",
      "Epoch 1: val_loss improved from inf to 0.02585, saving model to kim-cnn-model-on-text.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m839s\u001b[0m 3s/step - accuracy: 0.8832 - loss: 0.2442 - val_accuracy: 0.9959 - val_loss: 0.0258\n",
      "Epoch 2/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9949 - loss: 0.0264\n",
      "Epoch 2: val_loss improved from 0.02585 to 0.01679, saving model to kim-cnn-model-on-text.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m780s\u001b[0m 3s/step - accuracy: 0.9949 - loss: 0.0264 - val_accuracy: 0.9974 - val_loss: 0.0168\n",
      "Epoch 3/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9974 - loss: 0.0140\n",
      "Epoch 3: val_loss improved from 0.01679 to 0.01109, saving model to kim-cnn-model-on-text.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m699s\u001b[0m 3s/step - accuracy: 0.9974 - loss: 0.0140 - val_accuracy: 0.9980 - val_loss: 0.0111\n",
      "Epoch 4/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9988 - loss: 0.0092\n",
      "Epoch 4: val_loss improved from 0.01109 to 0.00760, saving model to kim-cnn-model-on-text.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m719s\u001b[0m 3s/step - accuracy: 0.9988 - loss: 0.0092 - val_accuracy: 0.9982 - val_loss: 0.0076\n",
      "Epoch 5/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9991 - loss: 0.0053\n",
      "Epoch 5: val_loss improved from 0.00760 to 0.00636, saving model to kim-cnn-model-on-text.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m707s\u001b[0m 3s/step - accuracy: 0.9991 - loss: 0.0053 - val_accuracy: 0.9987 - val_loss: 0.0064\n",
      "Epoch 6/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9989 - loss: 0.0041\n",
      "Epoch 6: val_loss improved from 0.00636 to 0.00528, saving model to kim-cnn-model-on-text.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m717s\u001b[0m 3s/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 0.9987 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9997 - loss: 0.0025\n",
      "Epoch 7: val_loss did not improve from 0.00528\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m712s\u001b[0m 3s/step - accuracy: 0.9997 - loss: 0.0025 - val_accuracy: 0.9987 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9993 - loss: 0.0021\n",
      "Epoch 8: val_loss did not improve from 0.00528\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m702s\u001b[0m 3s/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.9987 - val_loss: 0.0053\n",
      "Epoch 9/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9997 - loss: 0.0017\n",
      "Epoch 9: val_loss improved from 0.00528 to 0.00497, saving model to kim-cnn-model-on-text.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m716s\u001b[0m 3s/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9989 - val_loss: 0.0050\n",
      "Epoch 10/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9993 - loss: 0.0021\n",
      "Epoch 10: val_loss did not improve from 0.00497\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m771s\u001b[0m 3s/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.9987 - val_loss: 0.0052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f8ad9a7a70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# ModelCheckpoint to save the best model based on validation loss\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='kim-cnn-model-on-text.h5',      # Filepath where the model will be saved\n",
    "    monitor='val_loss',            # Metric to monitor\n",
    "    save_best_only=True,           # Only save the model if val_loss improves\n",
    "    verbose=1                     # Print messages when the model is saved\n",
    ")\n",
    "\n",
    "# Train the model with the callbacks\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 109ms/step - accuracy: 0.5083 - loss: 0.9301\n",
      "Test Loss: 0.9405768513679504\n",
      "Test Accuracy: 0.5001877546310425\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 148ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3996\n",
      "           1       1.00      1.00      1.00      3993\n",
      "\n",
      "    accuracy                           1.00      7989\n",
      "   macro avg       1.00      1.00      1.00      7989\n",
      "weighted avg       1.00      1.00      1.00      7989\n",
      "\n",
      "[[3993    3]\n",
      " [   6 3987]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Generate predicted probabilities\n",
    "y_pred_prob = model.predict(x_test)\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "# Convert one-hot encoded y_test back to class labels\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# y_test is one-hot encoded, so convert to class labels\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test_labels, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sb.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predictions on validation data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('kim-cnn-model-on-text.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer-on-text.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the validation data\n",
    "df_val = pd.read_csv('validation_data.csv')\n",
    "\n",
    "# Convert texts to sequences using the same tokenizer (assumed to be loaded or defined)\n",
    "sequences_val = tokenizer.texts_to_sequences(df_val['text'])\n",
    "\n",
    "# Pad the sequences using the same max_sequence_length as in training\n",
    "x_val = pad_sequences(sequences_val, maxlen=max_sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 110ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate predictions (probabilities)\n",
    "pred_probs = model.predict(x_val)\n",
    "\n",
    "# Convert probabilities to class labels (0 or 1)\n",
    "pred_labels = np.argmax(pred_probs, axis=1)\n",
    "\n",
    "# Add predictions to your dataframe\n",
    "df_val['predicted_label'] = pred_labels\n",
    "\n",
    "# Save the dataframe to a new CSV file (format similar to validation_data.csv)\n",
    "df_val.to_csv('predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
