{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Kim-CNN Word2Vec-based Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from gensim) (1.26.3)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from gensim) (1.11.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.8.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\007t\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import KeyedVectors\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploring The Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the Text File\n",
    "file_path = 'data.csv'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    news = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.countplot(x='label',data=news)\n",
    "plt.title(\"Distrbution of labels\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Frequancy\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Split the data into Traine - Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate the features and the target variable\n",
    "X = news['text']\n",
    "y = news['label']               \n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Preprocess Your Data**\n",
    "\n",
    "**Tokenization & Padding:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen max sequence length (95th percentile): 868\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# 1. a. Tokenize the train text\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(x_train)\n",
    "\n",
    "# 1. b. Tokenize the train text\n",
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "# 2. Compute the 95th percentile of these lengths\n",
    "train_sequence_lengths = [len(seq) for seq in sequences_train]\n",
    "max_length = int(np.percentile(train_sequence_lengths, 95))\n",
    "print(\"Chosen max sequence length (95th percentile):\", max_length)\n",
    "\n",
    "# 3. Use the max length as the max_sequence_length for padding/truncation\n",
    "max_sequence_length = max_length\n",
    "x_train = pad_sequences(sequences_train, maxlen=max_sequence_length)\n",
    "\n",
    "max_sequence_length = max_length\n",
    "x_test = pad_sequences(sequences_test, maxlen=max_sequence_length)\n",
    "\n",
    "word_index = tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load word2vec modle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"../models/GoogleNews-vectors-negative300.bin.gz\"\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Prepare the Embedding Layer**\n",
    "\n",
    "**Embedding Matrix from Pre-trained Word2Vec:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_dim = 300  # Google News word2vec using 300D\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec_model:\n",
    "        embedding_matrix[i] = word2vec_model[word]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create an Embedding layer in Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\007T\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    input_dim=len(word_index) + 1,\n",
    "    output_dim=embedding_dim,\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=max_sequence_length,\n",
    "    trainable=False  # Use False to keep the embeddings fixed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Build the Kim-CNN Architecture**\n",
    "\n",
    "**Architecture Components:**\n",
    "\n",
    "**1. Input Layer:** Accepts the padded sequences.\n",
    "\n",
    "**2. Embedding Layer:** Converts word indices to word vectors.\n",
    "\n",
    "**3. Convolutional Layers:** Apply several 1D convolution filters with different kernel sizes (e.g., 3, 4, 5) to capture various n-gram features.\n",
    "\n",
    "**4. Global Max-Pooling:** For each filter, apply max pooling over the time dimension (i.e., across the sentence length) to capture the most significant feature.\n",
    "\n",
    "**5. Concatenation:** Merge the outputs of the different filters.\n",
    "\n",
    "**6. Dropout:** Apply dropout for regularization.\n",
    "\n",
    "**7. Dense Layer:** Final classification layer with a softmax (or sigmoid) activation for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">868</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">868</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">35,320,500</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">866</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">115,328</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">865</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">153,728</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">864</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">192,128</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooli… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n",
       "│                     │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">770</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m868\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m868\u001b[0m, \u001b[38;5;34m300\u001b[0m)  │ \u001b[38;5;34m35,320,500\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m866\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m115,328\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m865\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m153,728\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m864\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m192,128\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_max_pooli… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_max_pooli… │\n",
       "│                     │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │        \u001b[38;5;34m770\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,782,454</span> (136.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m35,782,454\u001b[0m (136.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">461,954</span> (1.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m461,954\u001b[0m (1.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,320,500</span> (134.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m35,320,500\u001b[0m (134.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, GlobalMaxPooling1D, Concatenate, Dropout, Dense\n",
    "\n",
    "# Define hyperparameters\n",
    "filter_sizes = [3, 4, 5]   # Different filter sizes for n-grams\n",
    "num_filters = 128          # Number of filters per size\n",
    "dropout_rate = 0.5\n",
    "num_classes = 2            # Adjust based on your classification task\n",
    "\n",
    "# Input layer\n",
    "sequence_input = Input(shape=(max_sequence_length,), dtype='int32')\n",
    "\n",
    "# Embedding layer (using the pre-trained word2vec embeddings)\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "# Create a convolution + pooling layer for each filter size\n",
    "conv_layers = []\n",
    "for filter_size in filter_sizes:\n",
    "    conv = Conv1D(\n",
    "        filters=num_filters,\n",
    "        kernel_size=filter_size,\n",
    "        activation='relu'\n",
    "    )(embedded_sequences)\n",
    "    \n",
    "    pool = GlobalMaxPooling1D()(conv)\n",
    "    conv_layers.append(pool)\n",
    "\n",
    "# Concatenate the pooled features from each filter\n",
    "if len(conv_layers) > 1:\n",
    "    merged = Concatenate()(conv_layers)\n",
    "else:\n",
    "    merged = conv_layers[0]\n",
    "\n",
    "# Apply dropout for regularization\n",
    "drop = Dropout(dropout_rate)(merged)\n",
    "\n",
    "# Final dense layer for classification\n",
    "preds = Dense(num_classes, activation='softmax')(drop)\n",
    "\n",
    "# Define the model\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31953, 868) (31953,)\n",
      "(7989, 868) (7989,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer-on-text.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and Evaluating the Model**\n",
    "\n",
    "Convert your labels to categorical format and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert binary labels (0 or 1) to one-hot encoded vectors (shape becomes (num_samples, 2))\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8829 - loss: 0.2447\n",
      "Epoch 1: val_loss improved from inf to 0.02585, saving model to kim-cnn-model-on-text.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m839s\u001b[0m 3s/step - accuracy: 0.8832 - loss: 0.2442 - val_accuracy: 0.9959 - val_loss: 0.0258\n",
      "Epoch 2/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9949 - loss: 0.0264\n",
      "Epoch 2: val_loss improved from 0.02585 to 0.01679, saving model to kim-cnn-model-on-text.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m780s\u001b[0m 3s/step - accuracy: 0.9949 - loss: 0.0264 - val_accuracy: 0.9974 - val_loss: 0.0168\n",
      "Epoch 3/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9974 - loss: 0.0140\n",
      "Epoch 3: val_loss improved from 0.01679 to 0.01109, saving model to kim-cnn-model-on-text.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m699s\u001b[0m 3s/step - accuracy: 0.9974 - loss: 0.0140 - val_accuracy: 0.9980 - val_loss: 0.0111\n",
      "Epoch 4/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9988 - loss: 0.0092\n",
      "Epoch 4: val_loss improved from 0.01109 to 0.00760, saving model to kim-cnn-model-on-text.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m719s\u001b[0m 3s/step - accuracy: 0.9988 - loss: 0.0092 - val_accuracy: 0.9982 - val_loss: 0.0076\n",
      "Epoch 5/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9991 - loss: 0.0053\n",
      "Epoch 5: val_loss improved from 0.00760 to 0.00636, saving model to kim-cnn-model-on-text.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m707s\u001b[0m 3s/step - accuracy: 0.9991 - loss: 0.0053 - val_accuracy: 0.9987 - val_loss: 0.0064\n",
      "Epoch 6/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9989 - loss: 0.0041\n",
      "Epoch 6: val_loss improved from 0.00636 to 0.00528, saving model to kim-cnn-model-on-text.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m717s\u001b[0m 3s/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 0.9987 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9997 - loss: 0.0025\n",
      "Epoch 7: val_loss did not improve from 0.00528\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m712s\u001b[0m 3s/step - accuracy: 0.9997 - loss: 0.0025 - val_accuracy: 0.9987 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9993 - loss: 0.0021\n",
      "Epoch 8: val_loss did not improve from 0.00528\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m702s\u001b[0m 3s/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.9987 - val_loss: 0.0053\n",
      "Epoch 9/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9997 - loss: 0.0017\n",
      "Epoch 9: val_loss improved from 0.00528 to 0.00497, saving model to kim-cnn-model-on-text.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m716s\u001b[0m 3s/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9989 - val_loss: 0.0050\n",
      "Epoch 10/10\n",
      "\u001b[1m179/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3:31\u001b[0m 3s/step - accuracy: 0.9993 - loss: 0.0022"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# ModelCheckpoint to save the best model based on validation loss\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='kim-cnn-model-on-text.h5',      # Filepath where the model will be saved\n",
    "    monitor='val_loss',            # Metric to monitor\n",
    "    save_best_only=True,           # Only save the model if val_loss improves\n",
    "    verbose=1                     # Print messages when the model is saved\n",
    ")\n",
    "\n",
    "# Train the model with the callbacks\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9651 - loss: 0.1042\n",
      "Test Loss: 0.10491104423999786\n",
      "Test Accuracy: 0.9642007946968079\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      3996\n",
      "           1       0.96      0.97      0.96      3993\n",
      "\n",
      "    accuracy                           0.96      7989\n",
      "   macro avg       0.96      0.96      0.96      7989\n",
      "weighted avg       0.96      0.96      0.96      7989\n",
      "\n",
      "[[3848  148]\n",
      " [ 138 3855]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Generate predicted probabilities\n",
    "y_pred_prob = model.predict(x_test)\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "# Convert one-hot encoded y_test back to class labels\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# y_test is one-hot encoded, so convert to class labels\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test_labels, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
